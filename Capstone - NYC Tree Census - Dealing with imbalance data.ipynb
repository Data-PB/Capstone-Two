{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "130ac237",
   "metadata": {},
   "source": [
    "## Capstone  - NYC Tree Census - Dealing with imbalance data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c193c76b",
   "metadata": {},
   "source": [
    "### Table of contents\n",
    "1. [Background](#Background)\n",
    "     -   1.1 [Data Source](#Data-Source)\n",
    "     -   1.2 [Objective](#Objective)\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b184685",
   "metadata": {},
   "source": [
    "## 1. Loading and Preparing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa772d9d",
   "metadata": {},
   "source": [
    "#### 1.1 Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a5de353a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import (cross_val_score, train_test_split)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1dcf7f5",
   "metadata": {},
   "source": [
    "*Successfully loaded all the required libraries*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d88f4883",
   "metadata": {},
   "source": [
    "#### 1.2 Load the cleaned data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69999e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('encoded_data_health.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "956645ff",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "  <strong>Success!</strong> Successfully loaded the cleaned and encoded file.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "691e58d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>tree_dbh</th>\n",
       "      <th>health</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>x_sp</th>\n",
       "      <th>y_sp</th>\n",
       "      <th>problem_count</th>\n",
       "      <th>curb_loc_OffsetFromCurb</th>\n",
       "      <th>curb_loc_OnCurb</th>\n",
       "      <th>...</th>\n",
       "      <th>trnk_light_No</th>\n",
       "      <th>trnk_light_Yes</th>\n",
       "      <th>trnk_other_No</th>\n",
       "      <th>trnk_other_Yes</th>\n",
       "      <th>brch_light_No</th>\n",
       "      <th>brch_light_Yes</th>\n",
       "      <th>brch_shoe_No</th>\n",
       "      <th>brch_shoe_Yes</th>\n",
       "      <th>brch_other_No</th>\n",
       "      <th>brch_other_Yes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Fair</td>\n",
       "      <td>40.723092</td>\n",
       "      <td>-73.844215</td>\n",
       "      <td>1027431.148</td>\n",
       "      <td>202756.7687</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>Fair</td>\n",
       "      <td>40.794111</td>\n",
       "      <td>-73.818679</td>\n",
       "      <td>1034455.701</td>\n",
       "      <td>228644.8374</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  tree_dbh health   latitude  longitude         x_sp  \\\n",
       "0           0         3   Fair  40.723092 -73.844215  1027431.148   \n",
       "1           1        21   Fair  40.794111 -73.818679  1034455.701   \n",
       "\n",
       "          y_sp  problem_count  curb_loc_OffsetFromCurb  curb_loc_OnCurb  ...  \\\n",
       "0  202756.7687              0                        0                1  ...   \n",
       "1  228644.8374              1                        0                1  ...   \n",
       "\n",
       "   trnk_light_No  trnk_light_Yes  trnk_other_No  trnk_other_Yes  \\\n",
       "0              1               0              1               0   \n",
       "1              1               0              1               0   \n",
       "\n",
       "   brch_light_No  brch_light_Yes  brch_shoe_No  brch_shoe_Yes  brch_other_No  \\\n",
       "0              1               0             1              0              1   \n",
       "1              1               0             1              0              1   \n",
       "\n",
       "   brch_other_Yes  \n",
       "0               0  \n",
       "1               0  \n",
       "\n",
       "[2 rows x 38 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f1ec5871",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\parij\\AppData\\Local\\Temp/ipykernel_31332/3812631323.py:1: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  df = df.drop('Unnamed: 0', 1)\n"
     ]
    }
   ],
   "source": [
    "df = df.drop('Unnamed: 0', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6417c518",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tree_dbh</th>\n",
       "      <th>health</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>x_sp</th>\n",
       "      <th>y_sp</th>\n",
       "      <th>problem_count</th>\n",
       "      <th>curb_loc_OffsetFromCurb</th>\n",
       "      <th>curb_loc_OnCurb</th>\n",
       "      <th>steward_1or2</th>\n",
       "      <th>...</th>\n",
       "      <th>trnk_light_No</th>\n",
       "      <th>trnk_light_Yes</th>\n",
       "      <th>trnk_other_No</th>\n",
       "      <th>trnk_other_Yes</th>\n",
       "      <th>brch_light_No</th>\n",
       "      <th>brch_light_Yes</th>\n",
       "      <th>brch_shoe_No</th>\n",
       "      <th>brch_shoe_Yes</th>\n",
       "      <th>brch_other_No</th>\n",
       "      <th>brch_other_Yes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>Fair</td>\n",
       "      <td>40.723092</td>\n",
       "      <td>-73.844215</td>\n",
       "      <td>1027431.148</td>\n",
       "      <td>202756.7687</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21</td>\n",
       "      <td>Fair</td>\n",
       "      <td>40.794111</td>\n",
       "      <td>-73.818679</td>\n",
       "      <td>1034455.701</td>\n",
       "      <td>228644.8374</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   tree_dbh health   latitude  longitude         x_sp         y_sp  \\\n",
       "0         3   Fair  40.723092 -73.844215  1027431.148  202756.7687   \n",
       "1        21   Fair  40.794111 -73.818679  1034455.701  228644.8374   \n",
       "\n",
       "   problem_count  curb_loc_OffsetFromCurb  curb_loc_OnCurb  steward_1or2  ...  \\\n",
       "0              0                        0                1             0  ...   \n",
       "1              1                        0                1             0  ...   \n",
       "\n",
       "   trnk_light_No  trnk_light_Yes  trnk_other_No  trnk_other_Yes  \\\n",
       "0              1               0              1               0   \n",
       "1              1               0              1               0   \n",
       "\n",
       "   brch_light_No  brch_light_Yes  brch_shoe_No  brch_shoe_Yes  brch_other_No  \\\n",
       "0              1               0             1              0              1   \n",
       "1              1               0             1              0              1   \n",
       "\n",
       "   brch_other_Yes  \n",
       "0               0  \n",
       "1               0  \n",
       "\n",
       "[2 rows x 37 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52091f7d",
   "metadata": {},
   "source": [
    "#### 1.3 setting variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "23ad0d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting X and y variables\n",
    "y = df['health'].values\n",
    "X = df.drop('health', axis=1).values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10825045",
   "metadata": {},
   "source": [
    "#### 1.4 Setting train and test data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "842ddcea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(481791, 36) (481791,)\n",
      "(160597, 36) (160597,)\n"
     ]
    }
   ],
   "source": [
    "# train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "361d5466",
   "metadata": {},
   "source": [
    "## 2. Machine Learning Models - Attempt One "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aa769b6",
   "metadata": {},
   "source": [
    "#### 2.1 Logistic Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2a832566",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set Accuracy Score:  0.8113559614023508\n",
      "Test Set Accuracy Score:  0.8113538858135582\n",
      "Classification Metrics \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.00      0.00      0.00     23719\n",
      "        Good       0.81      1.00      0.90    130301\n",
      "        Poor       0.00      0.00      0.00      6577\n",
      "\n",
      "    accuracy                           0.81    160597\n",
      "   macro avg       0.27      0.33      0.30    160597\n",
      "weighted avg       0.66      0.81      0.73    160597\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "\n",
    "lr = LogisticRegression(random_state=42)\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred = lr.predict(X_test)\n",
    "        \n",
    "# accuracy scores\n",
    "print( 'Training Set Accuracy Score: ', lr.score(X_train, y_train))\n",
    "print('Test Set Accuracy Score: ', lr.score(X_test, y_test))\n",
    "    \n",
    "# classification metrics\n",
    "print('Classification Metrics \\n')\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11302543",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.heatmap(confusion_matrix(y_test, y_pred), annot = True,cmap='YlGnBu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a7d5d53",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "  <strong>Finding!</strong> Logistics Regression Model resulted in 81% accuracy.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "435bddeb",
   "metadata": {},
   "source": [
    "#### 2.2 K-Nearest Neighbors (KNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "73b4d1ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9cbd4d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2fee7fec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "26d2d080",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a9a2b1f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set Accuracy Score:  0.8499183255810092\n",
      "Test Set Accuracy Score:  0.8010236803925354\n",
      "Classification Metrics \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.40      0.25      0.31     23719\n",
      "        Good       0.85      0.94      0.89    130301\n",
      "        Poor       0.38      0.06      0.10      6577\n",
      "\n",
      "    accuracy                           0.80    160597\n",
      "   macro avg       0.54      0.42      0.43    160597\n",
      "weighted avg       0.76      0.80      0.77    160597\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# accuracy scores\n",
    "print('Training Set Accuracy Score: ', knn.score(X_train, y_train))\n",
    "print('Test Set Accuracy Score: ', knn.score(X_test, y_test))\n",
    "    \n",
    "# classificatin report\n",
    "print('Classification Metrics \\n')\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8da1657e",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "  <strong>Finding!</strong> K-Nearest Neighbor Model resulted in 80% accuracy. It's getting towards overfitting\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfea8c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "Overfitting - reduce the complexity of model and regularization \n",
    "Underfitting - more data \n",
    "\n",
    "the problem can be at model level and class level"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "176e0c6b",
   "metadata": {},
   "source": [
    "#### 2.3 Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f16466d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set Accuracy Score:  0.9999854708784515\n",
      "Test Set Accuracy Score:  0.7415642882494692\n",
      "Classification Metrics \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.30      0.31      0.30     23719\n",
      "        Good       0.86      0.85      0.85    130301\n",
      "        Poor       0.17      0.18      0.18      6577\n",
      "\n",
      "    accuracy                           0.74    160597\n",
      "   macro avg       0.44      0.45      0.44    160597\n",
      "weighted avg       0.75      0.74      0.74    160597\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "decision_tree = DecisionTreeClassifier(random_state=42)\n",
    "decision_tree.fit(X_train, y_train)\n",
    "y_pred = decision_tree.predict(X_test)\n",
    "    \n",
    "    \n",
    "# accuracy scores\n",
    "print('Training Set Accuracy Score: ', decision_tree.score(X_train, y_train))\n",
    "print('Test Set Accuracy Score: ', decision_tree.score(X_test, y_test))\n",
    "\n",
    "# classification report\n",
    "print('Classification Metrics \\n')\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "919c9e27",
   "metadata": {},
   "source": [
    "#### 2.4 Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf441b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "svm_clf = svm.SVC()\n",
    "svm_clf.fit(X_train, y_train)\n",
    "y_pred = svm_clf.predict(X_test)\n",
    "\n",
    "# accuracy scores\n",
    "print('Training Set Accuracy Score: ', svm_clf.score(X_train, y_train))\n",
    "print('Test Set Accuracy Score: ', svm_clf.score(X_test, y_test))\n",
    "\n",
    "# classification report\n",
    "print('Classification Metrics \\n')\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "618f5a2b",
   "metadata": {},
   "source": [
    "#### 2.5 Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bcac8ab2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set Accuracy Score:  0.9999315055698426\n",
      "Test Set Accuracy Score:  0.814896915882613\n",
      "Classification Metrics \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.47      0.20      0.28     23719\n",
      "        Good       0.85      0.96      0.90    130301\n",
      "        Poor       0.39      0.12      0.19      6577\n",
      "\n",
      "    accuracy                           0.81    160597\n",
      "   macro avg       0.57      0.43      0.46    160597\n",
      "weighted avg       0.77      0.81      0.78    160597\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred = rf.predict(X_test)\n",
    "    \n",
    "    \n",
    "# accuracy scores\n",
    "print('Training Set Accuracy Score: ', rf.score(X_train, y_train))\n",
    "print('Test Set Accuracy Score: ', rf.score(X_test, y_test))\n",
    "    \n",
    "# classification report\n",
    "print('Classification Metrics \\n')\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "710c3989",
   "metadata": {},
   "source": [
    "#### 2.6 Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "99c38580",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set Accuracy Score:  0.8128856703425344\n",
      "Test Set Accuracy Score:  0.81292925770718\n",
      "Classification Metrics \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.51      0.01      0.02     23719\n",
      "        Good       0.81      1.00      0.90    130301\n",
      "        Poor       0.48      0.03      0.05      6577\n",
      "\n",
      "    accuracy                           0.81    160597\n",
      "   macro avg       0.60      0.35      0.32    160597\n",
      "weighted avg       0.76      0.81      0.73    160597\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "gradient_booster = GradientBoostingClassifier()\n",
    "gradient_booster.fit(X_train,y_train)\n",
    "y_pred = gradient_booster.predict(X_test)\n",
    "\n",
    "\n",
    "# accuracy scores\n",
    "print('Training Set Accuracy Score: ', gradient_booster.score(X_train, y_train))\n",
    "print('Test Set Accuracy Score: ', gradient_booster.score(X_test, y_test))\n",
    "    \n",
    "# classification report\n",
    "print('Classification Metrics \\n')\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c06923c2",
   "metadata": {},
   "source": [
    "## 4. Resampling the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "75523dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dividing the data by the health status\n",
    "\n",
    "poor = df[df['health']=='Poor']\n",
    "fair = df[df['health']=='Fair']\n",
    "good = df[df['health']=='Good']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a649275f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Poor:  (26309, 37)\n",
      "Fair:  (94874, 37)\n",
      "Good:  (521205, 37)\n"
     ]
    }
   ],
   "source": [
    "# print the shpes of the class\n",
    "print('Poor: ',poor.shape)\n",
    "print('Fair: ',fair.shape)\n",
    "print('Good: ',good.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "216c8bb1",
   "metadata": {},
   "source": [
    "### 4.1 Oversampling Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae9e8e71",
   "metadata": {},
   "source": [
    "### 4.1.1 Random oversampling using imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4cd219ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset shape Counter({'Good': 521205, 'Fair': 94874, 'Poor': 26309})\n",
      "Resample dataset shape Counter({'Fair': 521205, 'Good': 521205, 'Poor': 521205})\n"
     ]
    }
   ],
   "source": [
    "#import library\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from collections import Counter\n",
    "\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "\n",
    "# fit predictor and target varaible\n",
    "X_ros, y_ros = ros.fit_resample(X, y)\n",
    "\n",
    "print('Original dataset shape', Counter(y))\n",
    "print('Resample dataset shape', Counter(y_ros))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "deb05331",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1172711, 36) (1172711,)\n",
      "(390904, 36) (390904,)\n"
     ]
    }
   ],
   "source": [
    "# train test split\n",
    "X_train_rs, X_test_rs, y_train_rs, y_test_rs = train_test_split(X_ros, y_ros, test_size=0.25, random_state=42)\n",
    "\n",
    "print(X_train_rs.shape, y_train_rs.shape)\n",
    "print(X_test_rs.shape, y_test_rs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf274582",
   "metadata": {},
   "source": [
    "#### 4.1.1a Logistic Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1ddfed08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set Accuracy Score:  0.3325448469401242\n",
      "Test Set Accuracy Score:  0.33137292020547243\n",
      "Classification Metrics \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.32      0.02      0.03    130385\n",
      "        Good       0.33      0.55      0.41    129681\n",
      "        Poor       0.34      0.43      0.38    130838\n",
      "\n",
      "    accuracy                           0.33    390904\n",
      "   macro avg       0.33      0.33      0.27    390904\n",
      "weighted avg       0.33      0.33      0.27    390904\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "\n",
    "lr_rs = LogisticRegression(random_state=42)\n",
    "lr_rs.fit(X_train_rs, y_train_rs)\n",
    "y_pred_rs = lr_rs.predict(X_test_rs)\n",
    "        \n",
    "# accuracy scores\n",
    "print( 'Training Set Accuracy Score: ', lr_rs.score(X_train_rs, y_train_rs))\n",
    "print('Test Set Accuracy Score: ', lr_rs.score(X_test_rs, y_test_rs))\n",
    "    \n",
    "# classification metrics\n",
    "print('Classification Metrics \\n')\n",
    "print(classification_report(y_test_rs, y_pred_rs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf2640e4",
   "metadata": {},
   "source": [
    "#### 4.1.1b K-Nearest Neighbour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63026678",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn_rs = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_rs.fit(X_train_rs, y_train_rs)\n",
    "y_pred_rs = knn_rs.predict(X_test_rs)\n",
    "    \n",
    "\n",
    "# accuracy scores\n",
    "print('Accuracy Score, Training Set: ', knn_rs.score(X_train_rs, y_train_rs))\n",
    "print('Accuracy Score, Test Set: ', knn_rs.score(X_test_rs, y_test_rs))\n",
    "    \n",
    "# classificatin report\n",
    "print('Classification Metrics \\n')\n",
    "print(classification_report(y_test_rs, y_pred_rs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed61d64e",
   "metadata": {},
   "source": [
    "#### 4.1.1c Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ceb29b87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set Accuracy Score:  0.9999855036748184\n",
      "Test Set Accuracy Score:  0.9384733847696621\n",
      "Classification Metrics \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.88      0.99      0.93    130385\n",
      "        Good       0.99      0.82      0.90    129681\n",
      "        Poor       0.97      1.00      0.98    130838\n",
      "\n",
      "    accuracy                           0.94    390904\n",
      "   macro avg       0.94      0.94      0.94    390904\n",
      "weighted avg       0.94      0.94      0.94    390904\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "decision_tree_rs = DecisionTreeClassifier(random_state=42)\n",
    "decision_tree_rs.fit(X_train_rs, y_train_rs)\n",
    "y_pred_rs = decision_tree_rs.predict(X_test_rs)\n",
    "    \n",
    "    \n",
    "# accuracy scores\n",
    "print('Training Set Accuracy Score: ', decision_tree_rs.score(X_train_rs, y_train_rs))\n",
    "print('Test Set Accuracy Score: ', decision_tree_rs.score(X_test_rs, y_test_rs))\n",
    "\n",
    "# classification report\n",
    "print('Classification Metrics \\n')\n",
    "print(classification_report(y_test_rs, y_pred_rs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56496bc1",
   "metadata": {},
   "source": [
    "#### 4.1.1d Random Forest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "41cf3180",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set Accuracy Score:  0.9999735655246689\n",
      "Test Set Accuracy Score:  0.9596115670343613\n",
      "Classification Metrics \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.91      0.99      0.95    130385\n",
      "        Good       0.99      0.89      0.94    129681\n",
      "        Poor       0.98      1.00      0.99    130838\n",
      "\n",
      "    accuracy                           0.96    390904\n",
      "   macro avg       0.96      0.96      0.96    390904\n",
      "weighted avg       0.96      0.96      0.96    390904\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf_rs = RandomForestClassifier(random_state=42)\n",
    "rf_rs.fit(X_train_rs, y_train_rs)\n",
    "y_pred_rs = rf_rs.predict(X_test_rs)\n",
    "    \n",
    "    \n",
    "# accuracy scores\n",
    "print('Training Set Accuracy Score: ', rf_rs.score(X_train_rs, y_train_rs))\n",
    "print('Test Set Accuracy Score: ', rf_rs.score(X_test_rs, y_test_rs))\n",
    "    \n",
    "# classification report\n",
    "print('Classification Metrics \\n')\n",
    "print(classification_report(y_test_rs, y_pred_rs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f55e09d2",
   "metadata": {},
   "source": [
    "#### 4.1.1e Gradient Boosting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c92b5223",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set Accuracy Score:  0.45321822682655827\n",
      "Test Set Accuracy Score:  0.4528554325358656\n",
      "Classification Metrics \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.42      0.30      0.35    130385\n",
      "        Good       0.45      0.59      0.51    129681\n",
      "        Poor       0.48      0.47      0.48    130838\n",
      "\n",
      "    accuracy                           0.45    390904\n",
      "   macro avg       0.45      0.45      0.45    390904\n",
      "weighted avg       0.45      0.45      0.45    390904\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "gradient_booster_rs = GradientBoostingClassifier()\n",
    "gradient_booster_rs.fit(X_train_rs,y_train_rs)\n",
    "y_pred_rs = gradient_booster_rs.predict(X_test_rs)\n",
    "\n",
    "\n",
    "# accuracy scores\n",
    "print('Training Set Accuracy Score: ', gradient_booster_rs.score(X_train_rs, y_train_rs))\n",
    "print('Test Set Accuracy Score: ', gradient_booster_rs.score(X_test_rs, y_test_rs))\n",
    "    \n",
    "# classification report\n",
    "print('Classification Metrics \\n')\n",
    "print(classification_report(y_test_rs, y_pred_rs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "732f53ee",
   "metadata": {},
   "source": [
    "### 4.1.2 Synthetic minority oversampleing technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e757f156",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Origianl dataset shape: Counter({'Good': 521205, 'Fair': 94874, 'Poor': 26309})\n",
      "Resampple dataset shape: Counter({'Fair': 521205, 'Good': 521205, 'Poor': 521205})\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "\n",
    "smote = SMOTE()\n",
    "\n",
    "# fit target and predictor variable\n",
    "X_smote , y_smote = smote.fit_resample(X, y)\n",
    "\n",
    "print('Origianl dataset shape:', Counter(y))\n",
    "print('Resampple dataset shape:', Counter(y_smote))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "76046353",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1172711, 36) (1172711,)\n",
      "(390904, 36) (390904,)\n"
     ]
    }
   ],
   "source": [
    "# train test split\n",
    "X_train_smote, X_test_smote, y_train_smote, y_test_smote = train_test_split(X_smote, y_smote, test_size=0.25, random_state=42)\n",
    "\n",
    "print(X_train_smote.shape, y_train_smote.shape)\n",
    "print(X_test_smote.shape, y_test_smote.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23a03a9b",
   "metadata": {},
   "source": [
    "#### 4.1.2a Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9e4aca78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set Accuracy Score:  0.33286376609411866\n",
      "Test Set Accuracy Score:  0.33113245195751384\n",
      "Classification Metrics \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\parij\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\parij\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.00      0.00      0.00    130385\n",
      "        Good       0.33      0.54      0.41    129681\n",
      "        Poor       0.34      0.46      0.39    130838\n",
      "\n",
      "    accuracy                           0.33    390904\n",
      "   macro avg       0.22      0.33      0.26    390904\n",
      "weighted avg       0.22      0.33      0.26    390904\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\parij\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "\n",
    "lr_smote = LogisticRegression(random_state=42)\n",
    "lr_smote.fit(X_train_smote, y_train_smote)\n",
    "y_pred_smote = lr_smote.predict(X_test_smote)\n",
    "        \n",
    "# accuracy scores\n",
    "print( 'Training Set Accuracy Score: ', lr_smote.score(X_train_smote, y_train_smote))\n",
    "print('Test Set Accuracy Score: ', lr_smote.score(X_test_smote, y_test_smote))\n",
    "    \n",
    "# classification metrics\n",
    "print('Classification Metrics \\n')\n",
    "print(classification_report(y_test_smote, y_pred_smote))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "758cd97c",
   "metadata": {},
   "source": [
    "#### 4.1.2b K-Nearest Neighbour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b9347d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn_smote = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_smote.fit(X_train_smote, y_train_smote)\n",
    "y_pred_smote = knn_smote.predict(X_test_smote)\n",
    "    \n",
    "\n",
    "# accuracy scores\n",
    "print('Accuracy Score, Training Set: ', knn_smote.score(X_train_smote, y_train_smote))\n",
    "print('Accuracy Score, Test Set: ', knn_smote.score(X_test_smote, y_test_smote))\n",
    "    \n",
    "# classificatin report\n",
    "print('Classification Metrics \\n')\n",
    "print(classification_report(y_test_smote, y_pred_smote))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14be8c97",
   "metadata": {},
   "source": [
    "#### 4.1.2c Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "771c559f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set Accuracy Score:  0.9999940309249252\n",
      "Test Set Accuracy Score:  0.8016981151382436\n",
      "Classification Metrics \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.74      0.73      0.73    130385\n",
      "        Good       0.85      0.84      0.84    129681\n",
      "        Poor       0.82      0.84      0.83    130838\n",
      "\n",
      "    accuracy                           0.80    390904\n",
      "   macro avg       0.80      0.80      0.80    390904\n",
      "weighted avg       0.80      0.80      0.80    390904\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "decision_tree_smote = DecisionTreeClassifier(random_state=42)\n",
    "decision_tree_smote.fit(X_train_smote, y_train_smote)\n",
    "y_pred_smote = decision_tree_smote.predict(X_test_smote)\n",
    "    \n",
    "    \n",
    "# accuracy scores\n",
    "print('Training Set Accuracy Score: ', decision_tree_smote.score(X_train_smote, y_train_smote))\n",
    "print('Test Set Accuracy Score: ', decision_tree_smote.score(X_test_smote, y_test_smote))\n",
    "\n",
    "# classification report\n",
    "print('Classification Metrics \\n')\n",
    "print(classification_report(y_test_smote, y_pred_smote))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a1f136",
   "metadata": {},
   "source": [
    "#### 4.1.2d Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3a3ae317",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set Accuracy Score:  0.9999803873247544\n",
      "Test Set Accuracy Score:  0.8741097558479831\n",
      "Classification Metrics \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.87      0.79      0.83    130385\n",
      "        Good       0.85      0.93      0.89    129681\n",
      "        Poor       0.90      0.91      0.90    130838\n",
      "\n",
      "    accuracy                           0.87    390904\n",
      "   macro avg       0.87      0.87      0.87    390904\n",
      "weighted avg       0.87      0.87      0.87    390904\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf_smote = RandomForestClassifier(random_state=42)\n",
    "rf_smote.fit(X_train_smote, y_train_smote)\n",
    "y_pred_smote = rf_smote.predict(X_test_smote)\n",
    "    \n",
    "    \n",
    "# accuracy scores\n",
    "print('Training Set Accuracy Score: ', rf_smote.score(X_train_smote, y_train_smote))\n",
    "print('Test Set Accuracy Score: ', rf_smote.score(X_test_smote, y_test_smote))\n",
    "    \n",
    "# classification report\n",
    "print('Classification Metrics \\n')\n",
    "print(classification_report(y_test_smote, y_pred_smote))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f04ad02",
   "metadata": {},
   "source": [
    "#### 4.1.2e Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0c077644",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set Accuracy Score:  0.6226657718738888\n",
      "Test Set Accuracy Score:  0.6214825123303931\n",
      "Classification Metrics \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.57      0.33      0.41    130385\n",
      "        Good       0.64      0.99      0.78    129681\n",
      "        Poor       0.62      0.55      0.59    130838\n",
      "\n",
      "    accuracy                           0.62    390904\n",
      "   macro avg       0.61      0.62      0.59    390904\n",
      "weighted avg       0.61      0.62      0.59    390904\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "gradient_booster_smote = GradientBoostingClassifier()\n",
    "gradient_booster_smote.fit(X_train_smote,y_train_smote)\n",
    "y_pred_smote = gradient_booster_smote.predict(X_test_smote)\n",
    "\n",
    "\n",
    "# accuracy scores\n",
    "print('Training Set Accuracy Score: ', gradient_booster_smote.score(X_train_smote, y_train_smote))\n",
    "print('Test Set Accuracy Score: ', gradient_booster_smote.score(X_test_smote, y_test_smote))\n",
    "    \n",
    "# classification report\n",
    "print('Classification Metrics \\n')\n",
    "print(classification_report(y_test_smote, y_pred_smote))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c41d94b",
   "metadata": {},
   "source": [
    "### 4.1.3 BroderlineSMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8f839479",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Origianl dataset shape: Counter({'Good': 521205, 'Fair': 94874, 'Poor': 26309})\n",
      "Resampple dataset shape: Counter({'Fair': 521205, 'Good': 521205, 'Poor': 521205})\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import BorderlineSMOTE\n",
    "\n",
    "bsmote = BorderlineSMOTE(random_state=42)\n",
    "\n",
    "# fit target and predictor variable\n",
    "X_bsmote , y_bsmote = bsmote.fit_resample(X, y)\n",
    "\n",
    "print('Origianl dataset shape:', Counter(y))\n",
    "print('Resampple dataset shape:', Counter(y_bsmote))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "28aad7c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1172711, 36) (1172711,)\n",
      "(390904, 36) (390904,)\n"
     ]
    }
   ],
   "source": [
    "# train test split\n",
    "X_train_bsmote, X_test_bsmote, y_train_bsmote, y_test_bsmote = train_test_split(X_bsmote, y_bsmote, test_size=0.25, random_state=42)\n",
    "\n",
    "print(X_train_bsmote.shape, y_train_bsmote.shape)\n",
    "print(X_test_bsmote.shape, y_test_bsmote.shape) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5379b12",
   "metadata": {},
   "source": [
    "#### 4.1.3a Logisitc Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a203d3ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set Accuracy Score:  0.33924726552407203\n",
      "Test Set Accuracy Score:  0.3388888320406033\n",
      "Classification Metrics \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.34      0.40      0.37    130385\n",
      "        Good       0.33      0.15      0.21    129681\n",
      "        Poor       0.34      0.46      0.39    130838\n",
      "\n",
      "    accuracy                           0.34    390904\n",
      "   macro avg       0.34      0.34      0.32    390904\n",
      "weighted avg       0.34      0.34      0.32    390904\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "\n",
    "lr_bsmote = LogisticRegression(random_state=42)\n",
    "lr_bsmote.fit(X_train_bsmote, y_train_bsmote)\n",
    "y_pred_bsmote = lr_bsmote.predict(X_test_bsmote)\n",
    "        \n",
    "# accuracy scores\n",
    "print( 'Training Set Accuracy Score: ', lr_bsmote.score(X_train_bsmote, y_train_bsmote))\n",
    "print('Test Set Accuracy Score: ', lr_bsmote.score(X_test_bsmote, y_test_bsmote))\n",
    "    \n",
    "# classification metrics\n",
    "print('Classification Metrics \\n')\n",
    "print(classification_report(y_test_bsmote, y_pred_bsmote))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bd3d0b7",
   "metadata": {},
   "source": [
    "#### 4.1.3b K-Nearest Negibhour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "378b21ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn_bsmote = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_bsmote.fit(X_train_bsmote, y_train_bsmote)\n",
    "y_pred_bsmote = knn_bsmote.predict(X_test_bsmote)\n",
    "    \n",
    "\n",
    "# accuracy scores\n",
    "print('Accuracy Score, Training Set: ', knn_bsmote.score(X_train_bsmote, y_train_bsmote))\n",
    "print('Accuracy Score, Test Set: ', knn_bsmote.score(X_test_bsmote, y_test_bsmote))\n",
    "    \n",
    "# classificatin report\n",
    "print('Classification Metrics \\n')\n",
    "print(classification_report(y_test_bsmote, y_pred_bsmote))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d6ba76e",
   "metadata": {},
   "source": [
    "#### 4.1.3c Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0b9fe7ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set Accuracy Score:  0.9999940309249252\n",
      "Test Set Accuracy Score:  0.8332045719665186\n",
      "Classification Metrics \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.79      0.77      0.78    130385\n",
      "        Good       0.85      0.84      0.84    129681\n",
      "        Poor       0.86      0.89      0.87    130838\n",
      "\n",
      "    accuracy                           0.83    390904\n",
      "   macro avg       0.83      0.83      0.83    390904\n",
      "weighted avg       0.83      0.83      0.83    390904\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "decision_tree_bsmote = DecisionTreeClassifier(random_state=42)\n",
    "decision_tree_bsmote.fit(X_train_bsmote, y_train_bsmote)\n",
    "y_pred_bsmote = decision_tree_bsmote.predict(X_test_bsmote)\n",
    "    \n",
    "    \n",
    "# accuracy scores\n",
    "print('Training Set Accuracy Score: ', decision_tree_bsmote.score(X_train_bsmote, y_train_bsmote))\n",
    "print('Test Set Accuracy Score: ', decision_tree_bsmote.score(X_test_bsmote, y_test_bsmote))\n",
    "\n",
    "# classification report\n",
    "print('Classification Metrics \\n')\n",
    "print(classification_report(y_test_bsmote, y_pred_bsmote))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf9c1ee7",
   "metadata": {},
   "source": [
    "#### 4.1.3d Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e7ff4155",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set Accuracy Score:  0.9999778291497223\n",
      "Test Set Accuracy Score:  0.8986119354112518\n",
      "Classification Metrics \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.90      0.83      0.86    130385\n",
      "        Good       0.86      0.93      0.90    129681\n",
      "        Poor       0.94      0.93      0.94    130838\n",
      "\n",
      "    accuracy                           0.90    390904\n",
      "   macro avg       0.90      0.90      0.90    390904\n",
      "weighted avg       0.90      0.90      0.90    390904\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf_bsmote = RandomForestClassifier(random_state=42)\n",
    "rf_bsmote.fit(X_train_bsmote, y_train_bsmote)\n",
    "y_pred_bsmote = rf_bsmote.predict(X_test_bsmote)\n",
    "    \n",
    "    \n",
    "# accuracy scores\n",
    "print('Training Set Accuracy Score: ', rf_bsmote.score(X_train_bsmote, y_train_bsmote))\n",
    "print('Test Set Accuracy Score: ', rf_bsmote.score(X_test_bsmote, y_test_bsmote))\n",
    "    \n",
    "# classification report\n",
    "print('Classification Metrics \\n')\n",
    "print(classification_report(y_test_bsmote, y_pred_bsmote))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edcf7762",
   "metadata": {},
   "source": [
    "#### 4.1.3e Gradient Boosting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0771e30f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set Accuracy Score:  0.6325744364979948\n",
      "Test Set Accuracy Score:  0.6301649509854081\n",
      "Classification Metrics \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.58      0.36      0.44    130385\n",
      "        Good       0.65      0.99      0.78    129681\n",
      "        Poor       0.63      0.55      0.59    130838\n",
      "\n",
      "    accuracy                           0.63    390904\n",
      "   macro avg       0.62      0.63      0.60    390904\n",
      "weighted avg       0.62      0.63      0.60    390904\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "gradient_booster_bsmote = GradientBoostingClassifier()\n",
    "gradient_booster_bsmote.fit(X_train_bsmote,y_train_bsmote)\n",
    "y_pred_bsmote = gradient_booster_bsmote.predict(X_test_bsmote)\n",
    "\n",
    "\n",
    "# accuracy scores\n",
    "print('Training Set Accuracy Score: ', gradient_booster_bsmote.score(X_train_bsmote, y_train_bsmote))\n",
    "print('Test Set Accuracy Score: ', gradient_booster_bsmote.score(X_test_bsmote, y_test_bsmote))\n",
    "    \n",
    "# classification report\n",
    "print('Classification Metrics \\n')\n",
    "print(classification_report(y_test_bsmote, y_pred_bsmote))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3778200c",
   "metadata": {},
   "source": [
    "### 4.1.4 SVMsmote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "af008788",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_31332/35001332.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# fit target and predictor variable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mX_svm\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0my_svm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msvm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_resample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Origianl dataset shape:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCounter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\imblearn\\base.py\u001b[0m in \u001b[0;36mfit_resample\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m     81\u001b[0m         )\n\u001b[0;32m     82\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 83\u001b[1;33m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit_resample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     84\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m         y_ = (\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\imblearn\\over_sampling\\_smote\\filter.py\u001b[0m in \u001b[0;36m_fit_resample\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    416\u001b[0m                 \u001b[0msupport_vector\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatnonzero\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogical_not\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnoise_bool\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    417\u001b[0m             )\n\u001b[1;32m--> 418\u001b[1;33m             danger_bool = self._in_danger_noise(\n\u001b[0m\u001b[0;32m    419\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn_m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msupport_vector\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_sample\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"danger\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    420\u001b[0m             )\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\imblearn\\over_sampling\\_smote\\base.py\u001b[0m in \u001b[0;36m_in_danger_noise\u001b[1;34m(self, nn_estimator, samples, target_class, y, kind)\u001b[0m\n\u001b[0;32m    188\u001b[0m             \u001b[0mA\u001b[0m \u001b[0mboolean\u001b[0m \u001b[0marray\u001b[0m \u001b[0mwhere\u001b[0m \u001b[1;32mTrue\u001b[0m \u001b[0mrefer\u001b[0m \u001b[0mto\u001b[0m \u001b[0msamples\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdanger\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mnoise\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    189\u001b[0m         \"\"\"\n\u001b[1;32m--> 190\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn_estimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkneighbors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_distance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    191\u001b[0m         \u001b[0mnn_label\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mtarget_class\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    192\u001b[0m         \u001b[0mn_maj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnn_label\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\neighbors\\_base.py\u001b[0m in \u001b[0;36mkneighbors\u001b[1;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[0;32m    750\u001b[0m                 \u001b[0mkwds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meffective_metric_params_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    751\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 752\u001b[1;33m             chunked_results = list(\n\u001b[0m\u001b[0;32m    753\u001b[0m                 pairwise_distances_chunked(\n\u001b[0;32m    754\u001b[0m                     \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\pairwise.py\u001b[0m in \u001b[0;36mpairwise_distances_chunked\u001b[1;34m(X, Y, reduce_func, metric, n_jobs, working_memory, **kwds)\u001b[0m\n\u001b[0;32m   1725\u001b[0m             \u001b[0mchunk_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mD_chunk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1726\u001b[0m             \u001b[0mD_chunk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreduce_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mD_chunk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1727\u001b[1;33m             \u001b[0m_check_chunk_size\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mD_chunk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchunk_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1728\u001b[0m         \u001b[1;32myield\u001b[0m \u001b[0mD_chunk\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1729\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\pairwise.py\u001b[0m in \u001b[0;36m_check_chunk_size\u001b[1;34m(reduced, chunk_size)\u001b[0m\n\u001b[0;32m   1510\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1511\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1512\u001b[1;33m \u001b[1;32mdef\u001b[0m \u001b[0m_check_chunk_size\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreduced\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchunk_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1513\u001b[0m     \u001b[1;34m\"\"\"Checks chunk is a sequence of expected size or a tuple of same.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1514\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mreduced\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SVMSMOTE\n",
    "from collections import Counter\n",
    "\n",
    "svm = SVMSMOTE(random_state=42)\n",
    "\n",
    "# fit target and predictor variable\n",
    "X_svm , y_svm = svm.fit_resample(X, y)\n",
    "\n",
    "print('Origianl dataset shape:', Counter(y))\n",
    "print('Resampple dataset shape:', Counter(y_svm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e933e1e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "X_train_svm, X_test_svm, y_train_svm, y_test_svm = train_test_split(X_svm, y_svm, test_size=0.25, random_state=42)\n",
    "\n",
    "print(X_train_svm.shape, y_train_svm.shape)\n",
    "print(X_test_svm.shape, y_test_svm.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef04eec3",
   "metadata": {},
   "source": [
    "#### 4.1.3a Logistic Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0873a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "\n",
    "lr_svm = LogisticRegression(random_state=42)\n",
    "lr_svm.fit(X_train_svm, y_train_svm)\n",
    "y_pred_svm = lr_svm.predict(X_test_svm)\n",
    "        \n",
    "# accuracy scores\n",
    "print( 'Training Set Accuracy Score: ', lr_svm.score(X_train_svm, y_train_svm))\n",
    "print('Test Set Accuracy Score: ', lr_svm.score(X_test_svm, y_test_svm))\n",
    "    \n",
    "# classification metrics\n",
    "print('Classification Metrics \\n')\n",
    "print(classification_report(y_test_svm, y_pred_svm))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "498632aa",
   "metadata": {},
   "source": [
    "#### 4.1.3b K-Nearest Negibhour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d88b7971",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn_svm = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_svm.fit(X_train_svm, y_train_svm)\n",
    "y_pred_svm = knn_svm.predict(X_test_svm)\n",
    "    \n",
    "\n",
    "# accuracy scores\n",
    "print('Accuracy Score, Training Set: ', knn_svm.score(X_train_svm, y_train_svm))\n",
    "print('Accuracy Score, Test Set: ', knn_svm.score(X_test_svm, y_test_svm))\n",
    "    \n",
    "# classificatin report\n",
    "print('Classification Metrics \\n')\n",
    "print(classification_report(y_test_svm, y_pred_svm))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98c446c4",
   "metadata": {},
   "source": [
    "#### 4.1.3c Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249540e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "decision_tree_svm = DecisionTreeClassifier(random_state=42)\n",
    "decision_tree_svm.fit(X_train_svm, y_train_svm)\n",
    "y_pred_svm = decision_tree_svm.predict(X_test_svm)\n",
    "    \n",
    "    \n",
    "# accuracy scores\n",
    "print('Training Set Accuracy Score: ', decision_tree_svm.score(X_train_svm, y_train_svm))\n",
    "print('Test Set Accuracy Score: ', decision_tree_svm.score(X_test_smote, y_test_svm))\n",
    "\n",
    "# classification report\n",
    "print('Classification Metrics \\n')\n",
    "print(classification_report(y_test_svm, y_pred_svm))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "341e5eb1",
   "metadata": {},
   "source": [
    "#### 4.1.3d Random Forest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52015727",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf_svm = RandomForestClassifier(random_state=42)\n",
    "rf_svm.fit(X_train_svm, y_train_svm)\n",
    "y_pred_svm = rf_svm.predict(X_test_svm)\n",
    "    \n",
    "    \n",
    "# accuracy scores\n",
    "print('Training Set Accuracy Score: ', rf_svm.score(X_train_svm, y_train_svm))\n",
    "print('Test Set Accuracy Score: ', rf_svm.score(X_test_svm, y_test_svm))\n",
    "    \n",
    "# classification report\n",
    "print('Classification Metrics \\n')\n",
    "print(classification_report(y_test_svm, y_pred_svm))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a81c39b5",
   "metadata": {},
   "source": [
    "#### 4.1.3e Gradient Boosting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c46ec4e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "gradient_booster_svm = GradientBoostingClassifier()\n",
    "gradient_booster_svm.fit(X_train_svm,y_train_svm)\n",
    "y_pred_svm = gradient_booster_svm.predict(X_test_svm)\n",
    "\n",
    "\n",
    "# accuracy scores\n",
    "print('Training Set Accuracy Score: ', gradient_booster_svm.score(X_train_svm, y_train_svm))\n",
    "print('Test Set Accuracy Score: ', gradient_booster_svm.score(X_test_svm, y_test_svm))\n",
    "    \n",
    "# classification report\n",
    "print('Classification Metrics \\n')\n",
    "print(classification_report(y_test_svm, y_pred_svm))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09cf401c",
   "metadata": {},
   "source": [
    "### 4.1.5 AdaSYN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fc22dae3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Origianl dataset shape: Counter({'Good': 521205, 'Fair': 94874, 'Poor': 26309})\n",
      "Resampple dataset shape: Counter({'Good': 521205, 'Poor': 518554, 'Fair': 517354})\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import ADASYN\n",
    "from collections import Counter\n",
    "\n",
    "ada = ADASYN(random_state=42)\n",
    "\n",
    "# fit target and predictor variable\n",
    "X_ada , y_ada = ada.fit_resample(X, y)\n",
    "\n",
    "print('Origianl dataset shape:', Counter(y))\n",
    "print('Resampple dataset shape:', Counter(y_ada))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5a499b58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1167834, 36) (1167834,)\n",
      "(389279, 36) (389279,)\n"
     ]
    }
   ],
   "source": [
    "# train test split\n",
    "X_train_ada, X_test_ada, y_train_ada, y_test_ada = train_test_split(X_ada, y_ada, test_size=0.25, random_state=42)\n",
    "\n",
    "print(X_train_ada.shape, y_train_ada.shape)\n",
    "print(X_test_ada.shape, y_test_ada.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da2c577f",
   "metadata": {},
   "source": [
    "#### 4.1.5a Logistic Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c824db93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set Accuracy Score:  0.33718490812906626\n",
      "Test Set Accuracy Score:  0.33577459868115156\n",
      "Classification Metrics \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\parij\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\parij\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.33      0.22      0.26    129890\n",
      "        Good       0.34      0.79      0.47    129552\n",
      "        Poor       0.00      0.00      0.00    129837\n",
      "\n",
      "    accuracy                           0.34    389279\n",
      "   macro avg       0.22      0.34      0.25    389279\n",
      "weighted avg       0.22      0.34      0.25    389279\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\parij\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "\n",
    "lr_ada = LogisticRegression(random_state=42)\n",
    "lr_ada.fit(X_train_ada, y_train_ada)\n",
    "y_pred_ada = lr_ada.predict(X_test_ada)\n",
    "        \n",
    "# accuracy scores\n",
    "print( 'Training Set Accuracy Score: ', lr_ada.score(X_train_ada, y_train_ada))\n",
    "print('Test Set Accuracy Score: ', lr_ada.score(X_test_ada, y_test_ada))\n",
    "    \n",
    "# classification metrics\n",
    "print('Classification Metrics \\n')\n",
    "print(classification_report(y_test_ada, y_pred_ada))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "849cc45f",
   "metadata": {},
   "source": [
    "#### 4.1.5b K-Nearest Neigbour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3583679b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn_ada = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_ada.fit(X_train_ada, y_train_ada)\n",
    "y_pred_ada = knn_ada.predict(X_test_ada)\n",
    "    \n",
    "\n",
    "# accuracy scores\n",
    "print('Accuracy Score, Training Set: ', knn_ada.score(X_train_ada, y_train_ada))\n",
    "print('Accuracy Score, Test Set: ', knn_ada.score(X_test_ada, y_test_ada))\n",
    "    \n",
    "# classificatin report\n",
    "print('Classification Metrics \\n')\n",
    "print(classification_report(y_test_ada, y_pred_ada))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f6a51cc",
   "metadata": {},
   "source": [
    "#### 4.1.5c Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6f60950b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set Accuracy Score:  0.9999922934252642\n",
      "Test Set Accuracy Score:  0.7933512981691795\n",
      "Classification Metrics \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.73      0.71      0.72    129890\n",
      "        Good       0.85      0.84      0.84    129552\n",
      "        Poor       0.80      0.83      0.82    129837\n",
      "\n",
      "    accuracy                           0.79    389279\n",
      "   macro avg       0.79      0.79      0.79    389279\n",
      "weighted avg       0.79      0.79      0.79    389279\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "decision_tree_ada = DecisionTreeClassifier(random_state=42)\n",
    "decision_tree_ada.fit(X_train_ada, y_train_ada)\n",
    "y_pred_ada = decision_tree_ada.predict(X_test_ada)\n",
    "    \n",
    "    \n",
    "# accuracy scores\n",
    "print('Training Set Accuracy Score: ', decision_tree_ada.score(X_train_ada, y_train_ada))\n",
    "print('Test Set Accuracy Score: ', decision_tree_ada.score(X_test_ada, y_test_ada))\n",
    "\n",
    "# classification report\n",
    "print('Classification Metrics \\n')\n",
    "print(classification_report(y_test_ada, y_pred_ada))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0106f281",
   "metadata": {},
   "source": [
    "#### 4.1.5d Random Forest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "53e7e955",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set Accuracy Score:  0.9999837305644467\n",
      "Test Set Accuracy Score:  0.8688318660909014\n",
      "Classification Metrics \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.87      0.77      0.82    129890\n",
      "        Good       0.85      0.93      0.89    129552\n",
      "        Poor       0.89      0.91      0.90    129837\n",
      "\n",
      "    accuracy                           0.87    389279\n",
      "   macro avg       0.87      0.87      0.87    389279\n",
      "weighted avg       0.87      0.87      0.87    389279\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf_ada = RandomForestClassifier(random_state=42)\n",
    "rf_ada.fit(X_train_ada, y_train_ada)\n",
    "y_pred_ada = rf_ada.predict(X_test_ada)\n",
    "    \n",
    "    \n",
    "# accuracy scores\n",
    "print('Training Set Accuracy Score: ', rf_ada.score(X_train_ada, y_train_ada))\n",
    "print('Test Set Accuracy Score: ', rf_ada.score(X_test_ada, y_test_ada))\n",
    "    \n",
    "# classification report\n",
    "print('Classification Metrics \\n')\n",
    "print(classification_report(y_test_ada, y_pred_ada))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0386361c",
   "metadata": {},
   "source": [
    "#### 4.1.5e Gradient Boosting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4ea6ce5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set Accuracy Score:  0.6247274869544815\n",
      "Test Set Accuracy Score:  0.6226639505341927\n",
      "Classification Metrics \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.87      0.77      0.82    129890\n",
      "        Good       0.85      0.93      0.89    129552\n",
      "        Poor       0.89      0.91      0.90    129837\n",
      "\n",
      "    accuracy                           0.87    389279\n",
      "   macro avg       0.87      0.87      0.87    389279\n",
      "weighted avg       0.87      0.87      0.87    389279\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "gradient_booster_ada = GradientBoostingClassifier()\n",
    "gradient_booster_ada.fit(X_train_ada,y_train_ada)\n",
    "y_pred_smote = gradient_booster_ada.predict(X_test_ada)\n",
    "\n",
    "\n",
    "# accuracy scores\n",
    "print('Training Set Accuracy Score: ', gradient_booster_ada.score(X_train_ada, y_train_ada))\n",
    "print('Test Set Accuracy Score: ', gradient_booster_ada.score(X_test_ada, y_test_ada))\n",
    "    \n",
    "# classification report\n",
    "print('Classification Metrics \\n')\n",
    "print(classification_report(y_test_ada, y_pred_ada))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d9b37f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d09a75b9",
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
